{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5N0yCre636sc",
   "metadata": {
    "id": "5N0yCre636sc"
   },
   "source": [
    "\n",
    "\n",
    "1. Definitions Based on Observations\n",
    "Search in Place:\n",
    "Small movements concentrated in a limited spatial area.\n",
    "Displacement vectors over time have minimal overall magnitude.\n",
    "No significant directional change.\n",
    "Backtracking:\n",
    "A substantial reversal of direction.\n",
    "Movement spans a considerable distance.\n",
    "A significant angular change in the displacement vectors (e.g., more than 160 degrees).\n",
    "\n",
    "2. Proposed Rules for Classification\n",
    "Rule for Search in Place: Total displacement in a sliding window should remain below a defined threshold.\n",
    "Angular changes should not vary significantly within the window (indicating limited directional shifts).\n",
    "Rule for Backtracking: Significant angular reversal (e.g., > 160 degrees).\n",
    "Displacement magnitude over the sliding window exceeds a defined threshold.\n",
    "\n",
    "\n",
    "3. Algorithm Enhancement\n",
    "The algorithm can be modified as follows: Compute total displacement and angular change within each sliding window.\n",
    "Apply thresholds for displacement and angular change:\n",
    "Classify windows with low displacement and angular change as \"Search in Place.\"\n",
    "Classify windows with high angular change and significant displacement as \"Backtracking.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wYiGXmMv7HMY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYiGXmMv7HMY",
    "outputId": "fd9636a0-7bc2-4187-959a-9356e84efdb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file 93_cleaned.txt: No columns to parse from file\n",
      "All trajectory plots saved to /Users/liziang/Desktop/Cornell/DAIL/All_Trajectory_Plots.pdf\n",
      "Backtracking table saved to /Users/liziang/Desktop/Cornell/DAIL/Table_Backtrack.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Define input/output paths\n",
    "data_folder = \"/Users/liziang/Desktop/Cornell/DAIL/content/Original_Tra\"\n",
    "output_pdf_file = \"/Users/liziang/Desktop/Cornell/DAIL/All_Trajectory_Plots.pdf\"\n",
    "output_csv_file = \"/Users/liziang/Desktop/Cornell/DAIL/Table_Backtrack.csv\"\n",
    "\n",
    "# Parameters\n",
    "T = 7  # Sliding window size in seconds\n",
    "theta_threshold = 175  # Angle threshold in degrees\n",
    "distance_threshold = 50.0  # Minimum movement distance to consider significant\n",
    "min_speed = 50.0\n",
    "angle_threshold = 15  # Min angle change to be considered significant\n",
    "window_size = 3  # Steps to check movement changes\n",
    "acceleration_threshold = 120  # Threshold for validating opposite acceleration\n",
    "\n",
    "# Initialize results storage\n",
    "backtracking_records = []\n",
    "pdf_pages = PdfPages(output_pdf_file)\n",
    "\n",
    "def preprocess_trajectory(t, x, y):\n",
    "    \"\"\" Preprocess trajectory data: removes unnecessary points and identifies straight-line movements. \"\"\"\n",
    "    t, x, y = t[2:], x[2:], y[2:]  # Remove first 2 points\n",
    "    y = -y  # Flip y-coordinates\n",
    "    t, x, y = t[50:], x[50:], y[50:]  # Remove first 50 points for backtracking\n",
    "\n",
    "    # Calculate displacement vectors\n",
    "    dx, dy = np.diff(x, prepend=x[0]), np.diff(y, prepend=y[0])\n",
    "    dt = np.diff(t, prepend=t[0])\n",
    "    dt[dt == 0] = np.finfo(float).eps  # Prevent division by zero\n",
    "\n",
    "    velocity_vectors = np.vstack((dx / dt, dy / dt)).T\n",
    "    norms = np.linalg.norm(velocity_vectors, axis=1)\n",
    "    norms[norms == 0] = np.finfo(float).eps\n",
    "    unit_vectors = velocity_vectors / norms[:, None]\n",
    "\n",
    "    angles = np.zeros(len(t))\n",
    "    straight_line_points = set()\n",
    "\n",
    "    for i in range(1, len(t) - window_size + 1):\n",
    "        v1, v2 = unit_vectors[i - 1], unit_vectors[i + window_size - 1]\n",
    "        dot_product = np.dot(v1, v2)\n",
    "        angle = np.arccos(np.clip(dot_product, -1.0, 1.0)) * (180 / np.pi)\n",
    "        angles[i] = angle\n",
    "\n",
    "        if angle < angle_threshold:\n",
    "            straight_line_points.update(range(i, i + window_size))\n",
    "\n",
    "    all_indices = np.arange(len(t))\n",
    "    significant_points = sorted(set(all_indices) - straight_line_points)\n",
    "\n",
    "    return t, x, y, significant_points, list(straight_line_points), velocity_vectors\n",
    "\n",
    "def detect_backtracking(t, x, y, velocity_vectors):\n",
    "    \"\"\" Detects backtracking using velocity direction changes. \"\"\"\n",
    "    dx, dy = np.diff(x, prepend=x[0]), np.diff(y, prepend=y[0])\n",
    "    dt = np.diff(t, prepend=t[0])\n",
    "    dt[dt == 0] = np.finfo(float).eps\n",
    "    displacements = np.vstack((dx / dt, dy / dt)).T\n",
    "\n",
    "    backtracking_indices = []\n",
    "    for i in range(len(t)):\n",
    "        t_prev_start, t_next_end = t[i] - T / 2, t[i] + T / 2\n",
    "        prev_indices, next_indices = np.where((t >= t_prev_start) & (t < t[i]))[0], np.where((t > t[i]) & (t <= t_next_end))[0]\n",
    "\n",
    "        if len(prev_indices) < 2 or len(next_indices) < 2:\n",
    "            continue\n",
    "\n",
    "        V_prev, V_next = np.mean(displacements[prev_indices], axis=0), np.mean(displacements[next_indices], axis=0)\n",
    "\n",
    "        if np.linalg.norm(V_prev) < min_speed or np.linalg.norm(V_next) < distance_threshold:\n",
    "            continue\n",
    "\n",
    "        dot_product = np.dot(V_prev, V_next)\n",
    "        norms = np.linalg.norm(V_prev) * np.linalg.norm(V_next)\n",
    "        if norms == 0:\n",
    "            continue\n",
    "\n",
    "        theta = np.arccos(np.clip(dot_product / norms, -1.0, 1.0)) * (180 / np.pi)\n",
    "\n",
    "        if theta > theta_threshold:\n",
    "            backtracking_indices.append(i)\n",
    "\n",
    "    # **Post-processing: Reduce duplicate detections**\n",
    "    grouped_indices = []\n",
    "    temp_group = [backtracking_indices[0]] if backtracking_indices else []\n",
    "\n",
    "    for idx in backtracking_indices[1:]:\n",
    "        if idx == temp_group[-1] + 1:\n",
    "            temp_group.append(idx)\n",
    "        else:\n",
    "            if len(temp_group) >= 2:\n",
    "                grouped_indices.append(temp_group)\n",
    "            temp_group = [idx]\n",
    "\n",
    "    if len(temp_group) >= 2:\n",
    "        grouped_indices.append(temp_group)\n",
    "\n",
    "    # Select only one **representative point** per group\n",
    "    filtered_backtracking = [g[len(g)//2] for g in grouped_indices]\n",
    "\n",
    "    return filtered_backtracking\n",
    "\n",
    "def validate_backtracking(t, x, y, backtracking_indices, velocity_vectors):\n",
    "    \"\"\" Validates backtracking based on acceleration direction. \"\"\"\n",
    "    acceleration_vectors = np.diff(velocity_vectors, axis=0)\n",
    "    if acceleration_vectors.shape[0] != velocity_vectors.shape[0]:\n",
    "        acceleration_vectors = np.vstack((np.zeros_like(velocity_vectors[0]), acceleration_vectors))\n",
    "\n",
    "    validated_backtracking = []\n",
    "    for i in backtracking_indices:\n",
    "        if i == 0 or i >= len(acceleration_vectors):\n",
    "            continue\n",
    "\n",
    "        acc_vec, vel_vec = acceleration_vectors[i], velocity_vectors[i - 1]\n",
    "        dot_product = np.dot(acc_vec, vel_vec)\n",
    "        norms = np.linalg.norm(acc_vec) * np.linalg.norm(vel_vec)\n",
    "\n",
    "        if norms == 0:\n",
    "            continue\n",
    "\n",
    "        angle = np.arccos(np.clip(dot_product / norms, -1.0, 1.0)) * (180 / np.pi)\n",
    "        if angle > acceleration_threshold:\n",
    "            validated_backtracking.append(i)\n",
    "\n",
    "    return validated_backtracking\n",
    "\n",
    "# Process all files in the folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\"_cleaned.txt\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        participant_id = filename.split(\"_\")[0]  # Extract participant ID\n",
    "\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, delimiter=',')\n",
    "            data = data.iloc[3:].reset_index(drop=True)\n",
    "            required_columns = {'UNIX', 'xHead', 'yHead', 'Task'}\n",
    "            if not required_columns.issubset(data.columns):\n",
    "                print(f\"Skipping file {filename}: Missing required columns\")\n",
    "                continue\n",
    "\n",
    "            data['Time'] = data['UNIX'] / 1000.0\n",
    "            t, x, y, task = data['Time'].values, data['xHead'].values, data['yHead'].values, data['Task'].values\n",
    "\n",
    "            # Apply preprocessing\n",
    "            t_proc, x_proc, y_proc, sig_points, straight_points, vel_vectors = preprocess_trajectory(t, x, y)\n",
    "\n",
    "            # Detect and validate backtracking\n",
    "            backtrack_idx = detect_backtracking(t_proc, x_proc, y_proc, vel_vectors)\n",
    "            validated_backtracking = validate_backtracking(t_proc, x_proc, y_proc, backtrack_idx, vel_vectors)\n",
    "\n",
    "            # Save backtracking records\n",
    "            for idx in validated_backtracking:\n",
    "                backtracking_records.append({\n",
    "                    'ParticipantID': participant_id,\n",
    "                    'Task': task[idx],\n",
    "                    'UnixTime': int(data.loc[idx, 'UNIX']),\n",
    "                    'CoordinateX': x_proc[idx],\n",
    "                    'CoordinateY': y_proc[idx]\n",
    "                })\n",
    "\n",
    "            # Plot results\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(x, -y, label='Original Trajectory', alpha=0.6, color='gray')\n",
    "            plt.scatter(np.array(x_proc)[sig_points], np.array(y_proc)[sig_points], color='red', label='Significant Points')\n",
    "            plt.scatter(np.array(x_proc)[straight_points], np.array(y_proc)[straight_points], color='green', alpha=0.1, label='Straight-Line Movement')\n",
    "\n",
    "            if validated_backtracking:\n",
    "                plt.scatter(\n",
    "                    np.array(x_proc)[validated_backtracking],\n",
    "                    np.array(y_proc)[validated_backtracking],\n",
    "                    color='blue',\n",
    "                    s=100,\n",
    "                    label='Validated Backtracking Moments'\n",
    "                )\n",
    "\n",
    "            plt.xlabel('X Position')\n",
    "            plt.ylabel('Y Position')\n",
    "            plt.title(f'Trajectory with Validated Backtracking Moments (Participant {participant_id})')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            pdf_pages.savefig()\n",
    "            plt.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Save backtracking table\n",
    "pd.DataFrame(backtracking_records).to_csv(output_csv_file, index=False)\n",
    "pdf_pages.close()\n",
    "\n",
    "print(f\"All trajectory plots saved to {output_pdf_file}\")\n",
    "print(f\"Backtracking table saved to {output_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def sort_pdf_by_participant(input_pdf, output_pdf):\n",
    "    # Read the PDF\n",
    "    reader = PdfReader(input_pdf)\n",
    "    pages_with_participants = []\n",
    "\n",
    "    # Extract participant numbers and associate with pages\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        match = re.search(r\"Participant (\\d+)\", text)\n",
    "        if match:\n",
    "            participant_number = int(match.group(1))\n",
    "            pages_with_participants.append((participant_number, i))\n",
    "\n",
    "    # Sort pages by participant number\n",
    "    pages_with_participants.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Create a new PDF with sorted pages\n",
    "    writer = PdfWriter()\n",
    "    for _, page_index in pages_with_participants:\n",
    "        writer.add_page(reader.pages[page_index])\n",
    "\n",
    "    # Save the sorted PDF\n",
    "    with open(output_pdf, \"wb\") as f:\n",
    "        writer.write(f)\n",
    "\n",
    "data_folder = \"/Users/liziang/Desktop/Cornell/DAIL/All_Trajectory_Plots_6.0.pdf\"\n",
    "output_pdf_file = \"/Users/liziang/Desktop/Cornell/DAIL/All_Trajectory_Plots_6.0_sorted.pdf\"\n",
    "        \n",
    "# Usage\n",
    "sort_pdf_by_participant(data_folder, output_pdf_file)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
